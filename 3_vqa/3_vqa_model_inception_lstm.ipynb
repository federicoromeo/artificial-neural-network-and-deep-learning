{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AicZNG52-rVX"
   },
   "source": [
    "# INCEPTION CNN and LSTM RNN\n",
    "In this first model for Visual Question Answering problem, we exploited InceptionV3 as transfer learning part for the Convolutional Neural Network, and Long Short Term Memory for Recurrent Neural Network part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1609882956180,
     "user": {
      "displayName": "Federico Romeo",
      "photoUrl": "https://lh6.googleusercontent.com/-t7-ZYUoSe3w/AAAAAAAAAAI/AAAAAAAAA8c/9aa1pe6GlnY/s64/photo.jpg",
      "userId": "18144303458962689975"
     },
     "user_tz": -60
    },
    "id": "FiLwi7HcT6Zm"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2423,
     "status": "ok",
     "timestamp": 1609882957784,
     "user": {
      "displayName": "Federico Romeo",
      "photoUrl": "https://lh6.googleusercontent.com/-t7-ZYUoSe3w/AAAAAAAAAAI/AAAAAAAAA8c/9aa1pe6GlnY/s64/photo.jpg",
      "userId": "18144303458962689975"
     },
     "user_tz": -60
    },
    "id": "KJqHEF3eT6Zn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for random operations, this let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# img shape\n",
    "img_h = 400\n",
    "img_w = 700\n",
    "\n",
    "num_classes = 58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we try to get the best partitioning of category by further attempts (explained in notebook \"1_data_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 212152,
     "status": "ok",
     "timestamp": 1609883167551,
     "user": {
      "displayName": "Federico Romeo",
      "photoUrl": "https://lh6.googleusercontent.com/-t7-ZYUoSe3w/AAAAAAAAAAI/AAAAAAAAA8c/9aa1pe6GlnY/s64/photo.jpg",
      "userId": "18144303458962689975"
     },
     "user_tz": -60
    },
    "id": "eJRYsmsm-rV5"
   },
   "outputs": [],
   "source": [
    "yes_no_prefixes   = [\"do\",\"does\",\"is\",\"are\",\"was\",\"were\",\"have\",\"might\",\"could\",\"can\",\"has\",\"will\",\"did\",\"would\",\"should\",\"if\"]\n",
    "counting_prefixes = [\"how\"]\n",
    "\n",
    "# Predict the category from a question\n",
    "\n",
    "def predict_category(question):\n",
    "    \n",
    "    if list(filter(question.lower().startswith, yes_no_prefixes)) != []:\n",
    "         return \"yes_no\" \n",
    "    elif list(filter(question.lower().startswith, counting_prefixes)) != [] or \"number\" in question.lower() or \"how many\" in question.lower():\n",
    "        return \"counting\"\n",
    "    \n",
    "    else:\n",
    "        return \"other\"\n",
    "    \n",
    "# Get the real category from the associated answer label\n",
    "\n",
    "def real_category(label):\n",
    "    \n",
    "    if label in [57,33]:\n",
    "        return \"yes_no\" \n",
    "    \n",
    "    elif label in [0,1,2,3,4,5]:\n",
    "        return \"counting\"\n",
    "    \n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAIMIdbNT6Zo"
   },
   "source": [
    "### Question-Answer Training Dataset\n",
    "Gather questions and answers from json, and then compute predictions on category (explained in notebook \"1_data_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 212957,
     "status": "ok",
     "timestamp": 1609883168365,
     "user": {
      "displayName": "Federico Romeo",
      "photoUrl": "https://lh6.googleusercontent.com/-t7-ZYUoSe3w/AAAAAAAAAAI/AAAAAAAAA8c/9aa1pe6GlnY/s64/photo.jpg",
      "userId": "18144303458962689975"
     },
     "user_tz": -60
    },
    "id": "klmuQFqq-rV6",
    "outputId": "e784957b-f86b-4507-a63b-2b47bc57bf45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions badly labelled: 622 over 58832\n",
      "In percentage: 1.057 %\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from os import getcwd, listdir\n",
    "from os.path import join\n",
    "import json\n",
    "\n",
    "dataset_dir  = join('../input/anndl-2020-vqa','VQA_Dataset')\n",
    "training_dir = join(dataset_dir, 'Images')\n",
    "\n",
    "labels_dict = { \n",
    "                '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, 'apple': 6,\n",
    "                'baseball': 7, 'bench': 8, 'bike': 9, 'bird': 10, 'black': 11, 'blanket': 12, 'blue': 13,\n",
    "                'bone': 14, 'book': 15, 'boy': 16, 'brown': 17, 'cat': 18, 'chair': 19, 'couch': 20,\n",
    "                'dog': 21, 'floor': 22, 'food': 23, 'football': 24, 'girl': 25, 'grass': 26, 'gray': 27,\n",
    "                'green': 28, 'left': 29, 'log': 30, 'man': 31, 'monkey bars': 32, 'no': 33, 'nothing': 34,\n",
    "                'orange': 35, 'pie': 36, 'plant': 37, 'playing': 38, 'red': 39, 'right': 40, 'rug': 41,\n",
    "                'sandbox': 42, 'sitting': 43, 'sleeping': 44, 'soccer': 45, 'squirrel': 46, 'standing': 47, \n",
    "                'stool': 48, 'sunny': 49, 'table': 50, 'tree': 51, 'watermelon': 52, 'white': 53, 'wine': 54, \n",
    "                'woman': 55, 'yellow': 56, 'yes': 57 \n",
    "              }\n",
    "\n",
    "train_dict  = {}\n",
    "with open(join(dataset_dir,'train_questions_annotations.json')) as json_file:\n",
    "    train_dict = json.load(json_file)\n",
    "\n",
    "# order json by 'image_id'    \n",
    "train_dict = dict(sorted(train_dict.items(), key=lambda x: int(x[1]['image_id'])))\n",
    "\n",
    "questions, labels_answers, answers, answers_id = [], [], [], []\n",
    "bad_label = 0\n",
    "\n",
    "for line in train_dict.items():\n",
    "\n",
    "    questions.append(line[1][\"question\"])\n",
    "    answers.append(line[1][\"answer\"])\n",
    "    labels_answers.append(labels_dict[line[1][\"answer\"]])\n",
    "    \n",
    "    if predict_category(line[1][\"question\"]) != real_category(labels_dict[line[1][\"answer\"]]):\n",
    "        bad_label += 1\n",
    "\n",
    "print(\"Number of questions badly labelled: \" + str(bad_label) + \" over \" + str(58832))\n",
    "print(\"In percentage: \" + str(bad_label/58832*100)[:5] + \" %\")\n",
    "\n",
    "# one-hot encoding for answers\n",
    "for a in answers:\n",
    "    answers_id.append(to_categorical(labels_dict.get(a), num_classes=58))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75sNY9KBT6Zo"
   },
   "source": [
    "## Tokenization\n",
    "Converts question's words to integers, and retrieve maximum question length. It will be used as a parameter for question input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5ADaD89lT6Zo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: 4640\n",
      "Max question length: 21\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_NUM_SENTENCES = 40000\n",
    "MAX_NUM_WORDS = 20000\n",
    "\n",
    "# QUESTIONS \n",
    "\n",
    "# Create Tokenizer to convert words to integers\n",
    "questions_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS)\n",
    "\n",
    "# pass the sentences retrieved from json\n",
    "questions_tokenizer.fit_on_texts(questions)\n",
    "\n",
    "# returns a list of lists of indexes referring to words inside that sentence (max of words)\n",
    "questions_tokenized = questions_tokenizer.texts_to_sequences(questions)\n",
    "\n",
    "# returns a dict with words lowercased in alphabetical order and indexed wrt cardinality\n",
    "questions_wtoi = questions_tokenizer.word_index\n",
    "print('Questions:', len(questions_wtoi))\n",
    "\n",
    "max_question_length = max(len(sentence) for sentence in questions_tokenized)\n",
    "print('Max question length:', max_question_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMHmTPzdT6Zo"
   },
   "source": [
    "### Padding sequences\n",
    "LSTM wants batches of same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "SsAMc718T6Zp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions encoder inputs shape: (58832, 21)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad (with 0) to max question length\n",
    "questions_encoded = pad_sequences(questions_tokenized, maxlen=max_question_length)\n",
    "\n",
    "print(\"Questions encoder inputs shape:\", questions_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform a 90% training/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52948"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "52948"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "52948"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [int(el[1]['image_id']) for el in train_dict.items()]   \n",
    "split = int(len(filenames)*0.90)  \n",
    "\n",
    "filenames_train = filenames[:split]\n",
    "filenames_valid = filenames[split:]\n",
    "len(filenames_train)\n",
    "len(filenames_valid)\n",
    "\n",
    "questions_encoded_train = questions_encoded[:split]\n",
    "questions_encoded_valid = questions_encoded[split:]\n",
    "len(questions_encoded_train)\n",
    "len(questions_encoded_valid)\n",
    "\n",
    "answers_train = answers_id[:split]\n",
    "answers_valid = answers_id[split:]\n",
    "len(answers_train)\n",
    "len(answers_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset that returns every time a tuple like:  ( [image, question], answer ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-BEj9f5G1PHQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50  import preprocess_input \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, filenames, questions, answers, preprocessing_function=preprocess_input, out_shape=[img_h,img_w],img_generator=ImageDataGenerator(rescale=1./255)):\n",
    "\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.filenames = filenames\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.out_shape = out_shape\n",
    "\n",
    "    def __len__(self): return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Read Image\n",
    "        curr_filename = self.filenames[index]\n",
    "        img = Image.open(join(training_dir, str(curr_filename) + '.png')).convert('RGB')\n",
    "\n",
    "        # Resize image\n",
    "        resized_img = img#.resize((img_h, img_w))\n",
    "        img_arr = np.array(resized_img)\n",
    "\n",
    "        return (img_arr, self.questions[index]), self.answers[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_custom_dataset = CustomDataset( filenames=filenames_valid, questions=questions_encoded_valid, answers=answers_valid )\n",
    "train_custom_dataset = CustomDataset( filenames=filenames_train, questions=questions_encoded_train, answers=answers_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally create the train and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: (((None, 400, 700, 3), (None, 21)), (None, 58)), types: ((tf.uint8, tf.int32), tf.int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: (((None, 400, 700, 3), (None, 21)), (None, 58)), types: ((tf.uint8, tf.int32), tf.int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_custom_dataset,\n",
    "                                               output_types=((tf.uint8,tf.int32), tf.int32),\n",
    "                                               output_shapes=(([img_h, img_w, 3],(max_question_length,)), (58,)) )\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_custom_dataset,\n",
    "                                               output_types=((tf.uint8,tf.int32), tf.int32),\n",
    "                                               output_shapes=(([img_h, img_w, 3],(max_question_length,)), (58,)) )\n",
    "valid_dataset = valid_dataset.batch(32)\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fyx28iuHT6Zp"
   },
   "source": [
    "# Model\n",
    "CNN: InceptionV3\n",
    "\n",
    "RNN: lsmt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "8IC7MPwGT6Zp"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 16\n",
    "\n",
    "# ENCODER\n",
    "\n",
    "encoder_input = tf.keras.Input(shape=[max_question_length])\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(len(questions_wtoi)+1, EMBEDDING_SIZE, input_length=max_question_length, mask_zero=True)\n",
    "encoder_embedding_out = encoder_embedding_layer(encoder_input)\n",
    "encoder_LSTM = tf.keras.layers.LSTM(units=128, return_state=False)(encoder_embedding_out)\n",
    "\n",
    "# INCEPTION\n",
    "\n",
    "inception = tf.keras.applications.InceptionV3(input_shape=(img_h, img_w, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in inception.layers: \n",
    "    layer.trainable = True\n",
    "    \n",
    "conv_layer = tf.keras.layers.Conv2D(256,1)(inception.output)\n",
    "inception_flatten = tf.keras.layers.Flatten()(conv_layer) #129024 \n",
    "inception_model = tf.keras.layers.Dense(units=128)(inception_flatten)\n",
    "\n",
    "# Combine CNN and RNN to create the final model\n",
    "\n",
    "merged = tf.keras.layers.Multiply()([encoder_LSTM, inception_model])\n",
    "classes = len(labels_dict)  #58\n",
    "output = tf.keras.layers.Dense(units=classes, activation='softmax')(merged)\n",
    "\n",
    "\n",
    "#MODEL\n",
    "\n",
    "vqa_model = tf.keras.Model(inputs=[inception.input,encoder_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "CBGKVJNYT6Zp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 400, 700, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 199, 349, 32) 864         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 199, 349, 32) 96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 199, 349, 32) 0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 197, 347, 32) 9216        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 197, 347, 32) 96          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 197, 347, 32) 0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 197, 347, 64) 18432       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 197, 347, 64) 192         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 197, 347, 64) 0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 98, 173, 64)  0           activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 98, 173, 80)  5120        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 98, 173, 80)  240         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 98, 173, 80)  0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 96, 171, 192) 138240      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 96, 171, 192) 576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 96, 171, 192) 0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 47, 85, 192)  0           activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 47, 85, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 47, 85, 64)   192         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 47, 85, 64)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 47, 85, 48)   9216        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 47, 85, 96)   55296       activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 47, 85, 48)   144         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 47, 85, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 47, 85, 48)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 47, 85, 96)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 47, 85, 192)  0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 47, 85, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 47, 85, 64)   76800       activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 47, 85, 96)   82944       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 47, 85, 32)   6144        average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 47, 85, 64)   192         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 47, 85, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 47, 85, 96)   288         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 47, 85, 32)   96          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 47, 85, 64)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 47, 85, 64)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 47, 85, 96)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 47, 85, 32)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 47, 85, 256)  0           activation_287[0][0]             \n",
      "                                                                 activation_289[0][0]             \n",
      "                                                                 activation_292[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 47, 85, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 47, 85, 64)   192         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 47, 85, 64)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 47, 85, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 47, 85, 96)   55296       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 47, 85, 48)   144         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 47, 85, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 47, 85, 48)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 47, 85, 96)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 47, 85, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 47, 85, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 47, 85, 64)   76800       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 47, 85, 96)   82944       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 47, 85, 64)   16384       average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 47, 85, 64)   192         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 47, 85, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 47, 85, 96)   288         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 47, 85, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 47, 85, 64)   0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 47, 85, 64)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 47, 85, 96)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 47, 85, 64)   0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 47, 85, 288)  0           activation_294[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_299[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 47, 85, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 47, 85, 64)   192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 47, 85, 64)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 47, 85, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 47, 85, 96)   55296       activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 47, 85, 48)   144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 47, 85, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 47, 85, 48)   0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 47, 85, 96)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 47, 85, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 47, 85, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 47, 85, 64)   76800       activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 47, 85, 96)   82944       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 47, 85, 64)   18432       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 47, 85, 64)   192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 47, 85, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 47, 85, 96)   288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 47, 85, 64)   192         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 47, 85, 64)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 47, 85, 64)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 47, 85, 96)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 47, 85, 64)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 47, 85, 288)  0           activation_301[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 47, 85, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 47, 85, 64)   192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 47, 85, 64)   0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 47, 85, 96)   55296       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 47, 85, 96)   288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 47, 85, 96)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 23, 42, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 23, 42, 96)   82944       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 23, 42, 384)  1152        conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 23, 42, 96)   288         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 23, 42, 384)  0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 23, 42, 96)   0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 23, 42, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 23, 42, 768)  0           activation_308[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 23, 42, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 23, 42, 128)  384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 23, 42, 128)  0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 23, 42, 128)  114688      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 23, 42, 128)  384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 23, 42, 128)  0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 23, 42, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 23, 42, 128)  114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 23, 42, 128)  384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 23, 42, 128)  384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 23, 42, 128)  0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 23, 42, 128)  0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 23, 42, 128)  114688      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 23, 42, 128)  114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 23, 42, 128)  384         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 23, 42, 128)  384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 23, 42, 128)  0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 23, 42, 128)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 23, 42, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 23, 42, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 23, 42, 192)  172032      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 23, 42, 192)  172032      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 23, 42, 192)  147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 23, 42, 192)  576         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 23, 42, 192)  576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 23, 42, 192)  576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 23, 42, 192)  576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 23, 42, 192)  0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 23, 42, 192)  0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 23, 42, 192)  0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 23, 42, 192)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 23, 42, 768)  0           activation_312[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "                                                                 activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 23, 42, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 23, 42, 160)  480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 23, 42, 160)  0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 23, 42, 160)  179200      activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 23, 42, 160)  480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 23, 42, 160)  0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 23, 42, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 23, 42, 160)  179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 23, 42, 160)  480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 23, 42, 160)  480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 23, 42, 160)  0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 23, 42, 160)  0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 23, 42, 160)  179200      activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 23, 42, 160)  179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 23, 42, 160)  480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 23, 42, 160)  480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 23, 42, 160)  0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 23, 42, 160)  0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 23, 42, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 23, 42, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 23, 42, 192)  215040      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 23, 42, 192)  215040      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 23, 42, 192)  147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 23, 42, 192)  576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 23, 42, 192)  576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 23, 42, 192)  576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 23, 42, 192)  576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 23, 42, 192)  0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 23, 42, 192)  0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 23, 42, 192)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 23, 42, 192)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 23, 42, 768)  0           activation_322[0][0]             \n",
      "                                                                 activation_325[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 23, 42, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 23, 42, 160)  480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 23, 42, 160)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 23, 42, 160)  179200      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 23, 42, 160)  480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 23, 42, 160)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 23, 42, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 23, 42, 160)  179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 23, 42, 160)  480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 23, 42, 160)  480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 23, 42, 160)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 23, 42, 160)  0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 23, 42, 160)  179200      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 23, 42, 160)  179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 23, 42, 160)  480         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 23, 42, 160)  480         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 23, 42, 160)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 23, 42, 160)  0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 23, 42, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 23, 42, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 23, 42, 192)  215040      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 23, 42, 192)  215040      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 23, 42, 192)  147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 23, 42, 192)  576         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 23, 42, 192)  576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 23, 42, 192)  576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 23, 42, 192)  576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 23, 42, 192)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 23, 42, 192)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 23, 42, 192)  0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 23, 42, 192)  0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 23, 42, 768)  0           activation_332[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 23, 42, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 23, 42, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 23, 42, 192)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 23, 42, 192)  258048      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 23, 42, 192)  576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 23, 42, 192)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 23, 42, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 23, 42, 192)  258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 23, 42, 192)  576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 23, 42, 192)  576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 23, 42, 192)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 23, 42, 192)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 23, 42, 192)  258048      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 23, 42, 192)  258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 23, 42, 192)  576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 23, 42, 192)  576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 23, 42, 192)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 23, 42, 192)  0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 23, 42, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 23, 42, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 23, 42, 192)  258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 23, 42, 192)  258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 23, 42, 192)  147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 23, 42, 192)  576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 23, 42, 192)  576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 23, 42, 192)  576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 23, 42, 192)  576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 23, 42, 192)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 23, 42, 192)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 23, 42, 192)  0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 23, 42, 192)  0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 23, 42, 768)  0           activation_342[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 23, 42, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 23, 42, 192)  576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 23, 42, 192)  0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 23, 42, 192)  258048      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 23, 42, 192)  576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 23, 42, 192)  0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 23, 42, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 23, 42, 192)  258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 23, 42, 192)  576         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 23, 42, 192)  576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 23, 42, 192)  0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 23, 42, 192)  0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 11, 20, 320)  552960      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 11, 20, 192)  331776      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 11, 20, 320)  960         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 11, 20, 192)  576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 11, 20, 320)  0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 11, 20, 192)  0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 11, 20, 768)  0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 11, 20, 1280) 0           activation_353[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 11, 20, 448)  573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 11, 20, 448)  1344        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 11, 20, 448)  0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 11, 20, 384)  491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 11, 20, 384)  1548288     activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 11, 20, 384)  1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 11, 20, 384)  1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 11, 20, 384)  0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 11, 20, 384)  0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 11, 20, 384)  442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 11, 20, 384)  442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 11, 20, 384)  442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 11, 20, 384)  442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 11, 20, 1280) 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 11, 20, 320)  409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 11, 20, 384)  1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 11, 20, 384)  1152        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 11, 20, 384)  1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 11, 20, 384)  1152        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 11, 20, 192)  245760      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 11, 20, 320)  960         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 11, 20, 384)  0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 11, 20, 384)  0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 11, 20, 384)  0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 11, 20, 384)  0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 11, 20, 192)  576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 11, 20, 320)  0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 11, 20, 768)  0           activation_360[0][0]             \n",
      "                                                                 activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 20, 768)  0           activation_364[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 11, 20, 192)  0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 11, 20, 2048) 0           activation_358[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 11, 20, 448)  917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 11, 20, 448)  1344        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 11, 20, 448)  0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 11, 20, 384)  786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 11, 20, 384)  1548288     activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 11, 20, 384)  1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 11, 20, 384)  1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 11, 20, 384)  0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 11, 20, 384)  0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 11, 20, 384)  442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 11, 20, 384)  442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 11, 20, 384)  442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 11, 20, 384)  442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, 11, 20, 2048) 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 11, 20, 320)  655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 11, 20, 384)  1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 11, 20, 384)  1152        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 11, 20, 384)  1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 11, 20, 384)  1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 11, 20, 192)  393216      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 11, 20, 320)  960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 11, 20, 384)  0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 11, 20, 384)  0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 11, 20, 384)  0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 11, 20, 384)  0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 11, 20, 192)  576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 11, 20, 320)  0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 11, 20, 768)  0           activation_369[0][0]             \n",
      "                                                                 activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 11, 20, 768)  0           activation_373[0][0]             \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 11, 20, 192)  0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 11, 20, 2048) 0           activation_367[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 11, 20, 256)  524544      mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 21, 16)       74256       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 56320)        0           conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 128)          74240       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          7209088     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128)          0           lstm_3[0][0]                     \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 58)           7482        multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 29,692,394\n",
      "Trainable params: 7,889,610\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vqa_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4Lw7k0pT6Zp"
   },
   "source": [
    "#### Optimization params to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "E_ihm4kvT6Zp"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Validation metrics\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Compile Model\n",
    "vqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model and add EarlyStopping to limit overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "AlbGCZQUT6Zp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "122/206 [================>.............] - ETA: 47s - loss: 3.1811 - accuracy: 0.2763"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-689ae73ba70e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_custom_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m               callbacks=callbacks )\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# How to visualize Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "vqa_model.fit(x=train_dataset,\n",
    "              validation_data=valid_dataset,\n",
    "              epochs=100,\n",
    "              steps_per_epoch=len(train_custom_dataset)/256,\n",
    "              validation_steps=len(valid_custom_dataset)/256,\n",
    "              batch_size=32, \n",
    "              callbacks=callbacks )\n",
    "\n",
    "# How to visualize Tensorboard\n",
    "\n",
    "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
    "# 2. localhost:PORT   <- in your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTNnjv0GReP_"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rt_CPlXjWP2X"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "    with open(join(results_dir, csv_fname), 'w') as f:\n",
    "        f.write('Id,Category\\n')\n",
    "        for key, value in results.items():\n",
    "            f.write(str(key) + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(dataset_dir,'test_questions.json')) as json_file:\n",
    "    test_dict = json.load(json_file)\n",
    "\n",
    "# order json by 'image_id'    \n",
    "test_dict = dict(sorted(test_dict.items(), key=lambda x: int(x[1]['image_id'])))\n",
    "\n",
    "test_questions, predicted_category, question_ids = [],[],[]\n",
    "\n",
    "for line in test_dict.items():\n",
    "    \n",
    "    question_ids.append(line[0])\n",
    "    test_questions.append(line[1][\"question\"])\n",
    "    predicted_category.append(predict_category(line[1][\"question\"]))\n",
    "        \n",
    "filenames_test = [int(el[1]['image_id']) for el in test_dict.items()]   \n",
    "len(filenames_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tokenize Test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer to convert words to integers\n",
    "test_questions_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS)\n",
    "\n",
    "### pass the sentences retrieved from txt\n",
    "test_questions_tokenizer.fit_on_texts(test_questions)\n",
    "\n",
    "### returns a list of lists of indexes referring to words inside that sentence (max of words)\n",
    "test_questions_tokenized = test_questions_tokenizer.texts_to_sequences(test_questions)\n",
    "\n",
    "### returns a dict with words lowercased in alphabetical order and indexed wrt cardinality\n",
    "test_questions_wtoi = test_questions_tokenizer.word_index\n",
    "print('Questions:', len(test_questions_wtoi))\n",
    "\n",
    "max_test_question_length = max(len(sentence) for sentence in test_questions_tokenized)\n",
    "print('Max question length:', max_test_question_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad test questions to max training questions length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad (with 0) to max question length\n",
    "questions_encoded_test = pad_sequences(test_questions_tokenized, maxlen=max_question_length)\n",
    "\n",
    "print(\"Questions encoder inputs shape:\", questions_encoded_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Dataset modified for test purpose, returns tuple like ( [image, question], -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm7nVJqnT6Zp"
   },
   "outputs": [],
   "source": [
    "class CustomDatasetTest(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, filenames, questions, preprocessing_function=preprocess_input, out_shape=[img_h,img_w],img_generator=ImageDataGenerator(rescale=1./255)):\n",
    "\n",
    "        self.questions = questions\n",
    "        self.filenames = filenames\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.out_shape = out_shape\n",
    "\n",
    "    def __len__(self): return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Read Image\n",
    "        curr_filename = self.filenames[index]\n",
    "        img = Image.open(join(training_dir, str(curr_filename) + '.png'))\n",
    "        rgb_img = img.convert('RGB')\n",
    "\n",
    "        # Resize image\n",
    "        resized_img = rgb_img#.resize((img_h, img_w))\n",
    "        img_arr = np.array(resized_img)\n",
    "\n",
    "        # Array of 58 zeros, to match the needed generator\n",
    "        zero = np.zeros(shape=(58,))\n",
    "\n",
    "        return (img_arr,self.questions[index]), zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_custom_dataset = CustomDatasetTest ( filenames=filenames_test, questions=questions_encoded_test )\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator( lambda: test_custom_dataset,\n",
    "                                               output_types=((tf.uint8,tf.int32), tf.int32),\n",
    "                                               output_shapes=(([img_h, img_w, 3],(max_question_length,)), (58,)) )\n",
    "test_dataset = test_dataset.batch(32)\n",
    "test_dataset = test_dataset.repeat()\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2SFEk4tnG_L"
   },
   "source": [
    "#### Argmax based on category of the answer (explained in notebook \"1_data_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3aEC95VWlP_"
   },
   "outputs": [],
   "source": [
    "labels_indexes = [i for i in range(0,len(labels_dict))]\n",
    "\n",
    "def disactivate(category):\n",
    "    \n",
    "    if category==\"yes_no\":\n",
    "        return [item for item in labels_indexes if item not in (33,57)]\n",
    "    \n",
    "    elif category==\"counting\":\n",
    "        return [item for item in labels_indexes if item not in (0,1,2,3,4,5)]\n",
    "    \n",
    "    else:\n",
    "        return [0,1,2,3,4,5,33,57]\n",
    "    \n",
    "\n",
    "def weighted_argmax(prediction,k):\n",
    "   \n",
    "    #print(\"Before:  \\n\" + str(prediction) +\"\\n\")\n",
    "    \n",
    "    weighted_prediction = prediction\n",
    "    category = predicted_category[k]\n",
    "    to_be_disactivated = disactivate(category)\n",
    "   \n",
    "    #print(\"Category: \", category, \"->\", \"Putting to zero\",len(to_be_disactivated),\"elements\",\"\\n\")\n",
    "\n",
    "    for j in to_be_disactivated:\n",
    "        weighted_prediction[j] = 0\n",
    "   \n",
    "    #print(\"Later:  \\n\" + str(weighted_prediction) +\"\\n\")\n",
    "    \n",
    "    return np.argmax(weighted_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = vqa_model.predict( x=test_dataset, steps=len(test_custom_dataset)/32 )\n",
    "\n",
    "if len(predictions) == len(filenames_test):\n",
    "    print(\"Correctly created\",len(predictions),\"entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n = random.randint(1,1000)\n",
    "\n",
    "# Image\n",
    "path = join(training_dir,str(filenames_test[n])+'.png')\n",
    "Image.open(path).resize((350,200), Image.NEAREST)\n",
    "\n",
    "# Question\n",
    "test_questions[n]\n",
    "\n",
    "# Predicted answer\n",
    "pr = weighted_argmax(predictions[n],n)\n",
    "switched_labels_dict = {int(y):x for x,y in labels_dict.items()}\n",
    "\"Predicted answer: \"+ switched_labels_dict[pr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actually generating dict for testing evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxcVFHbm-rWH"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "results = {}\n",
    "\n",
    "for p in predictions:\n",
    "\n",
    "    prediction = weighted_argmax(p,i)    \n",
    "    results[question_ids[i]] = str(prediction)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbESxSHLsqy5"
   },
   "outputs": [],
   "source": [
    "create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
