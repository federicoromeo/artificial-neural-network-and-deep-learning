{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET ENCODER\n",
    "In this model we decided to use resnet as transfer learning for the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5FnwOggnFIl"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOBDSA9BnFIx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED) \n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8bhsWQnnU-i",
    "outputId": "8fc3cc4a-99ab-4f37-ce0c-2e3802079e40"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH3lzlVqnFI2"
   },
   "source": [
    "## Usual generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N88wG50nFI3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    img_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                      width_shift_range=10,\n",
    "                                      height_shift_range=10,\n",
    "                                      zoom_range=0.3,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      fill_mode='reflect')\n",
    "    mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                       width_shift_range=10,\n",
    "                                       height_shift_range=10,\n",
    "                                       zoom_range=0.3,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode='reflect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptation of the starting kit function to convert RGB masks to array or correspondant class/color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEDTmdU0CRua"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def read_rgb_mask(img_path, resize_shape):\n",
    "\n",
    "    mask_img = Image.open(img_path)\n",
    "    mask_img = mask_img.resize(resize_shape, resample=Image.NEAREST)\n",
    "    mask_arr = np.array(mask_img)\n",
    "\n",
    "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
    "\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [254, 124, 18], axis=-1))]  = 0    #orange, ex 216\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1    #white\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))]   = 2    #red\n",
    "\n",
    "    return new_mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsieZk4aKhm6"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "  \"\"\"\n",
    "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
    "\n",
    "    3 main methods:\n",
    "      - __init__: save dataset params like directory, filenames..\n",
    "      - __len__: return the total number of samples in the dataset\n",
    "      - __getitem__: return a sample from the dataset\n",
    "\n",
    "    Note: \n",
    "      - the custom dataset return a single sample from the dataset. Then, we use \n",
    "        a tf.data.Dataset object to group samples into batches.\n",
    "      - in this case we have a different structure of the dataset in memory. \n",
    "        We have all the images in the same folder and the training and validation splits\n",
    "        are defined in text files.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None, out_shape=[1024,1024]):\n",
    "    if which_subset == 'training':\n",
    "      subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n",
    "    elif which_subset == 'validation':\n",
    "      subset_file = os.path.join(dataset_dir, 'Splits', 'val.txt')\n",
    "    \n",
    "    with open(subset_file, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "    \n",
    "    subset_filenames = []\n",
    "    for line in lines:\n",
    "      subset_filenames.append(line.strip()) \n",
    "\n",
    "    self.which_subset = which_subset\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.subset_filenames = subset_filenames\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "    self.out_shape = out_shape\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.subset_filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # Read Image\n",
    "    curr_filename = self.subset_filenames[index]\n",
    "    img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.jpg'))\n",
    "    mask = Image.open(os.path.join(self.dataset_dir, 'Annotations', curr_filename + '.png'))\n",
    "\n",
    "    # Resize image and mask\n",
    "    img = img.resize(self.out_shape)\n",
    "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "    \n",
    "    img_arr = np.array(img)\n",
    "    #0 1 2\n",
    "    mask_arr = read_rgb_mask(os.path.join(self.dataset_dir, 'Annotations', curr_filename + '.png'),[1024,1024])\n",
    "\n",
    "    # in this dataset 255 mask label is assigned to an additional class, which corresponds \n",
    "    # to the contours of the objects. We remove it for simplicity.\n",
    "    mask_arr[mask_arr == 255] = 0  #bg\n",
    "\n",
    "    mask_arr = np.expand_dims(mask_arr, -1)\n",
    "\n",
    "    if self.which_subset == 'training':\n",
    "      if self.img_generator is not None and self.mask_generator is not None:\n",
    "        # Perform data augmentation\n",
    "        # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
    "        # and we can apply it to the image using apply_transform\n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
    "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
    "        # Thus, when applied to the masks it will output 'interpolated classes', which\n",
    "        # is an unwanted behaviour. As a trick, we can transform each class mask \n",
    "        # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
    "        # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
    "            # from [0, 1] to {0, 1}\n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            # recover original class\n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    # Remove preprocessing because it blurred badly the images\n",
    "    #if self.preprocessing_function is not None:\n",
    "    #   img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "    return img_arr, np.float32(out_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use 1024x1024 images not to lose to many informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyrdiIh_PWjB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "img_h = 1024\n",
    "img_w = 1024\n",
    "\n",
    "# Here we trained our model just on bipbip dataset\n",
    "dataset_dir = os.path.join('/content/drive/My Drive','bipbip')\n",
    "\n",
    "dataset = CustomDataset(dataset_dir, 'training', img_generator=img_data_gen, mask_generator=mask_data_gen,\n",
    "                        preprocessing_function=preprocess_input, out_shape=[img_h,img_w])\n",
    "dataset_valid = CustomDataset(dataset_dir, 'validation', preprocessing_function=preprocess_input, out_shape=[img_h,img_w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batcsh_size= 8 to limit overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usz5SKPeQrOE"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "\n",
    "train_dataset = train_dataset.batch(8)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.batch(8)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign a color to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOBabUbmnFJE"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "evenly_spaced_interval = np.linspace(0, 1, 3)\n",
    "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
    "\n",
    "iterator = iter(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot some images next to their masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "9eunbPwWqPnB",
    "outputId": "cde97076-3055-45b1-aec6-cd1d1ad5de8f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "augmented_img, target = next(iterator)\n",
    "augmented_img = augmented_img[0]   # First element\n",
    "augmented_img = augmented_img  # denormalize\n",
    "\n",
    "target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
    "\n",
    "print(np.unique(target))\n",
    "\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "#default\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "\n",
    "for i in range(1, 4):\n",
    "    target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n",
    "\n",
    "ax[0].imshow(np.uint8(augmented_img))\n",
    "ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL : Convolutional Neural Network (CNN)\n",
    "RESNET: very useful as an encoder, it does something similar to the down sampling section of the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "553NrJXrFCZo",
    "outputId": "338f9640-6afc-48d4-8a6a-f783583a084b"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_h, img_w, 3) )\n",
    "\n",
    "# summarize the model\n",
    "resnet.summary()\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA1TGlOMnFJM"
   },
   "source": [
    "#### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvsdiF0TFTbt"
   },
   "outputs": [],
   "source": [
    "def create_model(depth, start_f, num_classes):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    model.add(resnet)\n",
    "    \n",
    "    start_f = 256\n",
    "        \n",
    "    # Decoder\n",
    "    for i in range(depth):\n",
    "        \n",
    "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_classes,kernel_size=(1, 1),strides=(1, 1),padding='same',activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model and visualize summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k97OK6CRnFJS",
    "outputId": "d19b0938-27dd-4535-8c9b-841aabdcfe81"
   },
   "outputs": [],
   "source": [
    "model = create_model(depth=5, start_f=8, num_classes=3)\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "# model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGzh16WTnFJW"
   },
   "source": [
    "#### Optimization params: prepare the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MlmYGVMnFJW"
   },
   "outputs": [],
   "source": [
    "# Loss: Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Here we define the intersection over union for each class in the batch.\n",
    "# Then we compute the final iou as the mean over classes\n",
    "def meanIoU(y_true, y_pred):\n",
    "  \n",
    "    # get predicted class from softmax\n",
    "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
    "\n",
    "    per_class_iou = []\n",
    "\n",
    "    for i in range(1,3): # exclude the background class 0\n",
    "        # Get prediction and target related to only a single class (i)\n",
    "        class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
    "        class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
    "        intersection = tf.reduce_sum(class_true * class_pred)\n",
    "        union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
    "\n",
    "        iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "        per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)\n",
    "\n",
    "# Validation metrics\n",
    "metrics = ['accuracy', meanIoU]\n",
    "\n",
    "# Visualize initialized weights\n",
    "# model.weights\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA6D_TBknFJZ"
   },
   "source": [
    "#### Training with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "3XiwaKZhnFJa",
    "outputId": "6f0e3e49-2d69-49c1-d80f-89b96d6cebf6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'multiclass_segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(dataset),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(dataset_valid), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuVw1q_NnFJh"
   },
   "source": [
    "## Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zo1JbCO5nFJh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "iterator = iter(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot some predicted masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "M75UjH7xxS7J",
    "outputId": "83ab471a-87fd-41af-8017-7b0d8729b40f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(8, 8))\n",
    "fig.show()\n",
    "image, target = next(iterator)\n",
    "\n",
    "image = image[0]\n",
    "target = target[0, ..., 0]\n",
    "\n",
    "out_sigmoid = model.predict(x=tf.expand_dims(image, 0))\n",
    "\n",
    "# Get predicted class as the index corresponding to the maximum value in the vector probability\n",
    "# predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n",
    "# predicted_class = predicted_class[0, ..., 0]\n",
    "predicted_class = tf.argmax(out_sigmoid, -1)\n",
    "\n",
    "out_sigmoid.shape\n",
    "\n",
    "predicted_class = predicted_class[0, ...]\n",
    "\n",
    "# Assign colors (just for visualization)\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "prediction_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "for i in range(1, 4):\n",
    "    target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n",
    "\n",
    "prediction_img[np.where(predicted_class == 0)] = [0, 0, 0]\n",
    "for i in range(1, 4):\n",
    "    prediction_img[np.where(predicted_class == i)] = np.array(colors[i-1])[:3] * 255\n",
    "\n",
    "ax[0].imshow(np.uint8(image))\n",
    "ax[0].set_title(\"IMAGE\")\n",
    "ax[1].imshow(np.uint8(target_img))\n",
    "ax[1].set_title(\"TARGET\")\n",
    "ax[2].imshow(np.uint8(prediction_img))\n",
    "ax[2].set_title(\"PREDICTION\")\n",
    "fig.canvas.draw()\n",
    "time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet_encoder_mod.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
