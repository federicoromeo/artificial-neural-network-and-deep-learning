{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE ANALYSIS\n",
    "### In this script, after having divided the images in folders, we inspected the data to get some useful informations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# In this list i'll save all image sizes\n",
    "all_sizes = []\n",
    "\n",
    "# In this list i'll save all *different* image sizes\n",
    "different_sizes = []\n",
    "\n",
    "# In this list i'll save all cardinality of every type of size\n",
    "cardinality = []\n",
    "\n",
    "# Dataset folder\n",
    "dataset_dir = os.path.join(os.getcwd(), \"MaskDatasetSizes\")\n",
    "\n",
    "# Here i have the list of all subdirectories\n",
    "dirs = os.listdir(dataset_dir)\n",
    "\n",
    "# File where we'll save the vertical images\n",
    "f = open(\"vertical.txt\",\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we cycled over the images to get their size, find the vertical ones, and create a second dataset on which rotate them without cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagesize\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "\n",
    "for dir in dirs:\n",
    "    sub = join(dataset_dir, dir)\n",
    "    subdirs = listdir(sub)\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        complete_subdir = join(join(dataset_dir,dir),subdir)\n",
    "        \n",
    "        # List of every file in dataset\n",
    "        onlyfiles = [f for f in listdir(complete_subdir) if isfile(join(complete_subdir, f))]\n",
    "       \n",
    "        # Decomment to compute the number of file in each subdirectory\n",
    "        #print(join(dir,subdir) + \"  : \" + str(len(onlyfiles)) + \" images\")\n",
    "\n",
    "        for file in onlyfiles:\n",
    "            image_complete_path = join(complete_subdir, file)\n",
    "            \n",
    "            # Get image size\n",
    "            width, height = imagesize.get(image_complete_path)\n",
    "            \n",
    "            # Understand which are the vertical images\n",
    "            if width < height:\n",
    "                \n",
    "                # Treat it like an horizontal one\n",
    "                width, height = height, width\n",
    "                \n",
    "                # ROTATION\n",
    "                img = Image.open(image_complete_path)\n",
    "                img = img.rotate(90 ,expand=True)\n",
    "                img.save(image_complete_path)\n",
    "               \n",
    "                # print their path on file, to get which are the vertical ones\n",
    "                f.write(join(dir,join(subdir, file)))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            cur_size = str(width) + \"_\" + str(height)\n",
    "            all_sizes.append(cur_size)\n",
    "            \n",
    "            if cur_size not in different_sizes:\n",
    "                different_sizes.append(cur_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we understood how many different types of image sizes were present, and created a dictionaire tuple for everyone of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d9d606be-1fae-45ba-9ad1-0be45cdb28f4",
    "_uuid": "bae982ff-89ef-43f0-99cc-0be32c146f66"
   },
   "outputs": [],
   "source": [
    "# Get the cardinality of each size, to understand which type of shape is in major number\n",
    "for different_size in different_sizes:\n",
    "    count = 0\n",
    "    for size in all_sizes:\n",
    "        if different_size == size:\n",
    "            count += 1\n",
    "    cardinality.append(count)\n",
    "\n",
    "# Build a dictionnaire to visualize gained data\n",
    "i = 0\n",
    "Total = dict()\n",
    "for i in range(len(different_sizes)):\n",
    "    width, height = different_sizes[i].split(\"_\")\n",
    "    Total[i] = {'Size': different_sizes[i] ,'Width': int(width), 'Height': int(height), 'Cardinality' : int(cardinality[i]) }\n",
    "\n",
    "# Sort dict by descending cardinality of size\n",
    "outputlist = sorted(Total.values(), key=lambda x:x['Cardinality'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we first computed the sums to get the average, and then we printed out our dictionary in order to see the most relevant tuples (of which we reported the most relevent below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_width, sum_height, card = 0,0,0\n",
    "for el in outputlist:\n",
    "    sum_width += el['Width'] * el['Cardinality']\n",
    "    sum_height += el['Height'] * el['Cardinality']\n",
    "    card += el['Cardinality']\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### {'Size': '612_408', 'Width': 612, 'Height': 408, 'Cardinality': 4325} \n",
    "##### {'Size': '612_407', 'Width': 612, 'Height': 407, 'Cardinality': 149}\n",
    "##### {'Size': '612_459', 'Width': 612, 'Height': 459, 'Cardinality': 133}\n",
    "##### {'Size': '612_409', 'Width':e 612, 'Height': 409, 'Cardinality': 105}\n",
    "##### {'Size': '612_612', 'Width': 612, 'Height': 612, 'Cardinality': 39}\n",
    "##### {'Size': '612_344', 'Width': 612, 'Height': 344, 'Cardinality': 31}\n",
    "\n",
    "### So we discovered that the dominant format is  [Width': 612, 'Height': 408], and there are 4325 images like that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we computed the weighted average of sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_w = sum_width / card\n",
    "med_h = sum_height / card\n",
    "print(\"\\nMedium weighted Width: \" + str(med_w))\n",
    "print(\"Medium weighted Height: \" + str(med_h) + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medium weighted size of images (weight=612 fixed, height=413.2 variable in range [256,612])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By running this script for the first time and printing every type of image size, we noticed that some images where vertical. So when we added the parameter target_size (X,Y), some images would have gone through a bad resize,  so we decided to create another dataset with only horizontal images, by rotating with the parameter expand=True, in order to prevent cropping. As we can see from this example:\n",
    "* this first image is the original vertical one;\n",
    "* the second one is what the \"flow_from_directory\" parameter target_size wuold create on out image;\n",
    "* the third one is our rotation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/RCB00L4/example.png\"  align=\"center\" alt=\"example\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then finally, we uploaded our second dataset with only horizontal images, over which we will try to see if any changes will occur on classifying"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
